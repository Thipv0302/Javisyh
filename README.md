## ğŸ® Tetris AI with Deep Q-Learning

This project implements a reinforcement learning agent that learns to play the game of **Tetris** using a **Deep Q-Network (DQN)** approach. The agent is trained from scratch and learns optimal moves through interaction with the Tetris environment.

### ğŸ“ Project Structure

```
JavisyH/
â”œâ”€â”€ train.py                # Training loop using DQN
â”œâ”€â”€ test.py                 # Script to evaluate the trained model
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ tetris.py           # Tetris game logic and environment
â”‚   â”œâ”€â”€ deep_q_network.py   # Neural network architecture for the DQN
â”œâ”€â”€ tensorboard/
â”‚   â””â”€â”€ events.out.*        # Logs for training visualization in TensorBoard
â”œâ”€â”€ trained_models/
â”‚   â””â”€â”€ tetris              # Trained model weights
```

### ğŸš€ How to Run

1. **Install Requirements**:

   ```bash
   pip install -r requirements.txt
   ```

2. **Train the Agent**:

   ```bash
   python train.py
   ```

3. **Evaluate the Model**:

   ```bash
   python test.py
   ```

4. **Visualize Training** (optional):

   ```bash
   tensorboard --logdir=tensorboard
   ```

### ğŸ§  Model

The Deep Q-Network (DQN) consists of a fully connected neural network that maps Tetris board states to Q-values representing the expected reward of each possible action.

### ğŸ¯ Features

* Custom Tetris environment (`tetris.py`)
* Deep Q-Learning with experience replay
* TensorBoard logging for training progress
* Pretrained model saving and loading

### ğŸ“Œ Notes

* The model performance may depend on training time and hyperparameter tuning.
* Works best with GPU acceleration for faster training.

